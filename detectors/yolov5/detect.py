# YOLO detection wrapper - Basic implementation for demo
import cv2
import numpy as np
from typing import List, Tuple, Dict, Any
import os

class SimpleDetector:
    """
    L·ªõp detector ƒë∆°n gi·∫£n d√πng cho demo, s·ª≠ d·ª•ng OpenCV's BasicBackgroundSubtractor 
    ho·∫∑c GroundTruth tr·ª±c ti·∫øp t·ª´ MOT16 n·∫øu c√≥
    """
    def __init__(self, conf_thres: float = 0.25, classes: List[int] = None):
        self.conf_thres = conf_thres
        self.classes = classes  # [0] cho ng∆∞·ªùi
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)
        self.frame_count = 0
        self.gt_data = None  # S·∫Ω ch·ª©a d·ªØ li·ªáu ground truth n·∫øu c√≥
        
        print(f"üì¶ S·ª≠ d·ª•ng OpenCV SimpleDetector cho demo. Ng∆∞·ª°ng: {conf_thres}")

    def load_gt_if_available(self, source_path: str):
        """
        T·∫£i d·ªØ li·ªáu ground truth n·∫øu path l√† MOT16 sequence
        """
        gt_path = os.path.join(source_path, "gt", "gt.txt")
        if os.path.exists(gt_path):
            print(f"T√¨m th·∫•y d·ªØ li·ªáu ground truth: {gt_path}")
            self.gt_data = {}
            total_objects = 0
            
            # ƒê·ªçc to√†n b·ªô file ground truth
            with open(gt_path, 'r') as f:
                for line in f:
                    fields = line.strip().split(',')
                    # Format MOT16: <frame_id>,<object_id>,<x>,<y>,<w>,<h>,<confidence>,<class_id>,<visibility>
                    frame_id = int(fields[0])
                    object_id = int(fields[1])
                    
                    # B·ªè qua c√°c ƒë·ªëi t∆∞·ª£ng kh√¥ng h·ª£p l·ªá
                    confidence = float(fields[6]) if len(fields) > 6 else 0
                    if confidence == 0:  # Ch·ªâ l·∫•y c√°c ƒë·ªëi t∆∞·ª£ng c√≥ confidence > 0
                        continue
                        
                    # L·∫•y th√¥ng tin v·ªã tr√≠ v√† k√≠ch th∆∞·ªõc
                    x, y, w, h = map(float, fields[2:6])
                    
                    # V·ªõi MOT16 class 1=person, c√°c class kh√°c th∆∞·ªùng kh√¥ng quan t√¢m
                    class_id = int(fields[7]) if len(fields) > 7 else 1
                    
                    # Ch·ªâ l·∫•y ng∆∞·ªùi (class 1) ho·∫∑c c√°c class c·∫ßn thi·∫øt
                    if class_id != 1 and (self.classes is not None and class_id not in self.classes):
                        continue
                    
                    # Chuy·ªÉn ƒë·ªïi t·ª´ class c·ªßa MOT sang class c·ªßa YOLO n·∫øu c·∫ßn
                    # MOT16: class 1 = person, YOLO: class 0 = person
                    yolo_class_id = 0 if class_id == 1 else class_id
                    
                    # Kh·ªüi t·∫°o danh s√°ch cho frame n·∫øu ch∆∞a c√≥
                    if frame_id not in self.gt_data:
                        self.gt_data[frame_id] = []
                    
                    # Th√™m ƒë·ªëi t∆∞·ª£ng v√†o danh s√°ch c·ªßa frame t∆∞∆°ng ·ª©ng
                    # Format: (class_id, confidence, [x, y, w, h])
                    self.gt_data[frame_id].append(
                        (yolo_class_id, confidence, [int(x), int(y), int(w), int(h)])
                    )
                    total_objects += 1
            
            # Th·ªëng k√™ s·ªë frame v√† ƒë·ªëi t∆∞·ª£ng
            unique_frames = len(self.gt_data)
            print(f"üöÄ ƒê√£ t·∫£i ground truth cho {unique_frames} frames, t·ªïng c·ªông {total_objects} ƒë·ªëi t∆∞·ª£ng")
            
            # In ra m·ªôt v√†i frame ƒë·∫ßu ti√™n ƒë·ªÉ debug
            first_10_frames = sorted(list(self.gt_data.keys()))[:10]
            for frame in first_10_frames:
                print(f"Frame {frame}: {len(self.gt_data[frame])} ƒë·ªëi t∆∞·ª£ng")
                
            return True
        return False

    def detect(self, frame: np.ndarray, frame_id: int = None) -> List[Tuple[int, float, List[int]]]:
        """
        Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng trong frame
        Args:
            frame: ·∫¢nh ƒë·∫ßu v√†o d·∫°ng numpy array (BGR)
            frame_id: ID c·ªßa frame (d√πng cho MOT16, b·∫Øt ƒë·∫ßu t·ª´ 1)
        Returns:
            List c√°c detection [class_id, confidence, [x, y, w, h]]
        """
        self.frame_count += 1
        
        # S·ª≠ d·ª•ng frame_id truy·ªÅn v√†o n·∫øu c√≥, n·∫øu kh√¥ng d√πng frame_count
        current_frame_id = frame_id if frame_id is not None else self.frame_count
        
        # Debug th√¥ng tin frame_count v·ªõi t·∫ßn su·∫•t th·∫•p h∆°n ƒë·ªÉ gi·∫£m b·ªõt th√¥ng tin
        if self.frame_count % 100 == 0:
            print(f"DEBUG DETECTOR: X·ª≠ l√Ω frame {self.frame_count}, MOT frame_id={current_frame_id}")
        
        # 1. Ki·ªÉm tra n·∫øu c√≥ d·ªØ li·ªáu ground truth cho frame hi·ªán t·∫°i
        if self.gt_data is not None and current_frame_id in self.gt_data:
            detections = self.gt_data[current_frame_id]
            
            # Cho bi·∫øt s·ªë l∆∞·ª£ng ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán
            if detections:
                # Ch·ªâ in log debug cho nh·ªØng frame c√≥ ƒë·ªëi t∆∞·ª£ng v√† theo t·∫ßn su·∫•t ph√π h·ª£p
                if self.frame_count % 20 == 0 or len(detections) > 5:
                    print(f"DEBUG DETECTOR: ƒê√£ t√¨m th·∫•y {len(detections)} ƒë·ªëi t∆∞·ª£ng trong frame {current_frame_id}")
            return detections
        
        # 2. N·∫øu kh√¥ng c√≥ ground truth, d√πng background subtraction
        fg_mask = self.bg_subtractor.apply(frame)
        
        # L·ªçc nhi·ªÖu
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        detections = []
        for contour in contours:
            # Lo·∫°i b·ªè c√°c contour qu√° nh·ªè
            if cv2.contourArea(contour) < 500:  # Ng∆∞·ª°ng di·ªán t√≠ch
                continue
                
            # L·∫•y bounding box
            x, y, w, h = cv2.boundingRect(contour)
            
            # Confidence gi·∫£ l·∫≠p d·ª±a tr√™n di·ªán t√≠ch
            area = cv2.contourArea(contour)
            confidence = min(1.0, area / 10000)  # Gi·ªõi h·∫°n max l√† 1.0
            
            # Ch·ªâ gi·ªØ l·∫°i c√°c detection c√≥ ƒë·ªô tin c·∫≠y cao
            if confidence >= self.conf_thres:
                class_id = 0  # M·∫∑c ƒë·ªãnh l√† class 'ng∆∞·ªùi'
                detections.append((class_id, confidence, [x, y, w, h]))
                
        return detections

# T·∫°o class alias ƒë·ªÉ tr√°nh ph·∫£i s·ª≠a code ·ªü c√°c n∆°i kh√°c
YOLOv5Detector = SimpleDetector
